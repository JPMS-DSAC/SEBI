{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "import tensorboard\n",
        "# from tensorflow.keras import to_categorical\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#creating extra data from current files  \n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import bert\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert import BertModelLayer\n",
        "\n",
        "from tensorflow.keras import initializers \n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import constraints\n",
        "\n",
        "from tensorflow.keras import activations \n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# from tensorflow.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "import tensorboard\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Layer,Dropout, LSTM, GRU, Bidirectional, TimeDistributed, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gVYg4R0XoWrY"
      },
      "outputs": [],
      "source": [
        "############################### path check (add path to data)\n",
        "root_path = ''\n",
        "list_of_files = []\n",
        "for root, dir, files in os.walk('../data'):\n",
        "  root_path = root\n",
        "  list_of_files = files\n",
        "  break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Annotated - CSV\n",
            "['1288072330011.csv', '1288673034598.csv', '1289452697301.csv', '1289903641088.csv', '1290062946166.csv', '1290154724736_NEG.csv', '1291175003856_NEG.csv', '1312279794560.csv', '1312280268805.csv', '1314613428609.csv', '1315463402543.csv', '1324544561749.csv', '1358769139907.csv', '1372652426612.csv', '1372830044081.csv', '1380795608703.csv', '1382959468059.csv', '1404099510806.csv', '1404444629445.csv', '1404800940434.csv', '1407404311694.csv', '1407404374671.csv', '1407404413828.csv', '1409133457223.csv', '1427283185104.csv', '1494587603795.csv', '1509190608413.csv', '1522238936458.csv', '1564575450353.csv']\n"
          ]
        }
      ],
      "source": [
        "print(root_path)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iSGn-SeoY8n",
        "outputId": "db11c12c-5d80-4163-987c-7bacd07314dc"
      },
      "outputs": [],
      "source": [
        "all_dataframes = []\n",
        "for filename in list_of_files:\n",
        "  file_path = root_path + '/' + filename\n",
        "  file_temp = pd.read_csv(file_path)\n",
        "  all_dataframes.append(file_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "8DUShph8ueDM",
        "outputId": "14106433-aa5a-4aa2-db76-4f2dd8d9d55e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence ID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F1288072330011_S1</td>\n",
              "      <td>material fact</td>\n",
              "      <td>1. The shares of Genus Commu Trade Limited (he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F1288072330011_S2</td>\n",
              "      <td>procedural fact</td>\n",
              "      <td>SEBI conducted an investigation in respect of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F1288072330011_S3</td>\n",
              "      <td>material fact</td>\n",
              "      <td>2. During the investigation period, the scrip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F1288072330011_S4</td>\n",
              "      <td>material fact</td>\n",
              "      <td>The price reached the period low (intra day) o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F1288072330011_S5</td>\n",
              "      <td>material fact</td>\n",
              "      <td>During the said period the total traded quanti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sentence ID            Label  \\\n",
              "0  F1288072330011_S1    material fact   \n",
              "1  F1288072330011_S2  procedural fact   \n",
              "2  F1288072330011_S3    material fact   \n",
              "3  F1288072330011_S4    material fact   \n",
              "4  F1288072330011_S5    material fact   \n",
              "\n",
              "                                            Sentence  \n",
              "0  1. The shares of Genus Commu Trade Limited (he...  \n",
              "1  SEBI conducted an investigation in respect of ...  \n",
              "2  2. During the investigation period, the scrip ...  \n",
              "3  The price reached the period low (intra day) o...  \n",
              "4  During the said period the total traded quanti...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_dataframes[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Zofd5s8yu-wQ"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame()\n",
        "result = result.append(all_dataframes,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_txt(txt):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    #only take words or numbers in\n",
        "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+', gaps=False)\n",
        "    tokens = tokenizer.tokenize(txt)\n",
        "    tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "def lemmatization(data):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_text = [lemmatizer.lemmatize(word) for word in data]\n",
        "    return ' '.join(lemmatized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Sentence ID            Label  \\\n",
            "0  F1288072330011_S1    material fact   \n",
            "1  F1288072330011_S2  procedural fact   \n",
            "2  F1288072330011_S3    material fact   \n",
            "3  F1288072330011_S4    material fact   \n",
            "4  F1288072330011_S5    material fact   \n",
            "\n",
            "                                            Sentence  \n",
            "0  1. The shares of Genus Commu Trade Limited (he...  \n",
            "1  SEBI conducted an investigation in respect of ...  \n",
            "2  2. During the investigation period, the scrip ...  \n",
            "3  The price reached the period low (intra day) o...  \n",
            "4  During the said period the total traded quanti...  \n"
          ]
        }
      ],
      "source": [
        "print(result.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result['token'] = result['Sentence'].map(tokenize_txt)\n",
        "# result['lemma'] = result['token'].map(lemmatization)\n",
        "# result['tok_size'] = result['token'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence ID    2264\n",
            "Label          2264\n",
            "Sentence       2264\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(result.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xFZqENusvEOI"
      },
      "outputs": [],
      "source": [
        "train_data = pd.DataFrame(columns= result.columns)\n",
        "val_data = pd.DataFrame(columns=result.columns)\n",
        "test_data = pd.DataFrame(columns=result.columns)\n",
        "for label in result.Label.unique():\n",
        "  temp_df = result[result['Label'] == label]\n",
        "  train_index = int(temp_df.shape[0]*0.85)\n",
        "  train_data = train_data.append(temp_df[:train_index])\n",
        "  test_data = test_data.append(temp_df[train_index:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cq0lbc9ZvUSc"
      },
      "outputs": [],
      "source": [
        "train_data.drop(columns = ['Sentence ID'],axis=1,inplace=True)\n",
        "test_data.drop(columns = ['Sentence ID'],axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "k2dLnXArvdTG",
        "outputId": "42bdc773-c23c-4f2f-fac3-ca75d459d050"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>material fact</td>\n",
              "      <td>1. The shares of Genus Commu Trade Limited (he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>material fact</td>\n",
              "      <td>2. During the investigation period, the scrip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>material fact</td>\n",
              "      <td>The price reached the period low (intra day) o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>material fact</td>\n",
              "      <td>During the said period the total traded quanti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>material fact</td>\n",
              "      <td>3. For the two months (July 01, 2004 to August...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Label                                           Sentence\n",
              "0  material fact  1. The shares of Genus Commu Trade Limited (he...\n",
              "2  material fact  2. During the investigation period, the scrip ...\n",
              "3  material fact  The price reached the period low (intra day) o...\n",
              "4  material fact  During the said period the total traded quanti...\n",
              "5  material fact  3. For the two months (July 01, 2004 to August..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean length of sentence: 35.17153284671533\n",
            "max length of sentence: 188\n",
            "std dev length of sentence: 23.503743535760414\n"
          ]
        }
      ],
      "source": [
        "train_data['l'] = train_data['Sentence'].apply(lambda x: len(str(x).split(' ')))\n",
        "print(\"mean length of sentence: \" + str(train_data.l.mean()))\n",
        "print(\"max length of sentence: \" + str(train_data.l.max()))\n",
        "print(\"std dev length of sentence: \" + str(train_data.l.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequence_length = 188"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['material fact',\n",
              " 'procedural fact',\n",
              " 'allegation',\n",
              " 'defendant claim',\n",
              " 'issues framed',\n",
              " 'statutory fact',\n",
              " 'subjective observation',\n",
              " 'violation',\n",
              " 'penalty',\n",
              " 'related fact']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes = train_data.Label.unique().tolist()\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test set size 227\n"
          ]
        }
      ],
      "source": [
        "max_features = 20000 # this is the number of words we care about\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\n",
        "tokenizer.fit_on_texts(result['Sentence'].values)\n",
        "\n",
        "# this takes our sentences and replaces each word with an integer\n",
        "X = tokenizer.texts_to_sequences(result['Sentence'].values)\n",
        "\n",
        "# we then pad the sequences so they're all the same length (sequence_length)\n",
        "X = pad_sequences(X, sequence_length)\n",
        "\n",
        "y = pd.get_dummies(result['Label']).values\n",
        "\n",
        "# where there isn't a test set, Kim keeps back 10% of the data for testing, I'm going to do the same since we have an ok amount to play with\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "print(\"test set size \" + str(len(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_callbacks = [EarlyStopping(patience=150, monitor=\"val_loss\"),  ModelCheckpoint(filepath='model_cnn3.hdf5', save_best_only=False, save_weights_only = False, monitor='val_loss', mode='auto',save_freq = 'epoch'),keras.callbacks.TensorBoard(log_dir=logdir)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "f = open('./glove.6B.200d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4059 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 200 # Kim uses 300 here\n",
        "num_filters = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4060\n"
          ]
        }
      ],
      "source": [
        "num_words = min(max_features, len(word_index)) + 1\n",
        "print(num_words)\n",
        "\n",
        "# first create a matrix of zeros, this is our embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "# for each word in out tokenizer lets try to find that work in our w2v model\n",
        "for word, i in word_index.items():\n",
        "    if i > max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # we found the word - add that words vector to the matrix\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # doesn't exist, assign a random vector\n",
        "        embedding_matrix[i] = np.random.randn(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs_2 = Input(shape=(sequence_length,), dtype='int32')\n",
        "\n",
        "# note the `trainable=False`, later we will make this layer trainable\n",
        "embedding_layer_2 = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=sequence_length,\n",
        "                            trainable=False)(inputs_2)\n",
        "\n",
        "reshape_2 = Reshape((sequence_length, embedding_dim, 1))(embedding_layer_2)\n",
        "\n",
        "conv_0_2 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\n",
        "conv_1_2 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\n",
        "conv_2_2 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_2)\n",
        "\n",
        "maxpool_0_2 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_2)\n",
        "maxpool_1_2 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_2)\n",
        "maxpool_2_2 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_2)\n",
        "\n",
        "concatenated_tensor_2 = Concatenate(axis=1)([maxpool_0_2, maxpool_1_2, maxpool_2_2])\n",
        "flatten_2 = Flatten()(concatenated_tensor_2)\n",
        "\n",
        "dropout_2 = Dropout(0.5)(flatten_2)\n",
        "output_2 = Dense(units=10, activation='softmax')(dropout_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 188)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 188, 200)     812000      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 188, 200, 1)  0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 186, 1, 100)  60100       reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 185, 1, 100)  80100       reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 184, 1, 100)  100100      reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 100)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 1, 100)    0           max_pooling2d_6[0][0]            \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 300)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 300)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           3010        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,055,310\n",
            "Trainable params: 243,310\n",
            "Non-trainable params: 812,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model_2 = Model(inputs=inputs_2, outputs=output_2)\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model_2.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_callbacks = [EarlyStopping(patience=150, monitor=\"val_loss\"),  ModelCheckpoint(filepath='model_cnn2.hdf5', save_best_only=True, save_weights_only = False, monitor='val_loss', mode='auto',save_freq = 'epoch'),keras.callbacks.TensorBoard(log_dir=logdir)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "51/51 [==============================] - 8s 40ms/step - loss: 3.6837 - accuracy: 0.3278 - val_loss: 2.2781 - val_accuracy: 0.3627\n",
            "Epoch 2/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2965 - accuracy: 0.3382 - val_loss: 2.2033 - val_accuracy: 0.3676\n",
            "Epoch 3/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2786 - accuracy: 0.3315 - val_loss: 2.2462 - val_accuracy: 0.3701\n",
            "Epoch 4/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3062 - accuracy: 0.3382 - val_loss: 2.2089 - val_accuracy: 0.2990\n",
            "Epoch 5/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3002 - accuracy: 0.3327 - val_loss: 2.2473 - val_accuracy: 0.3750\n",
            "Epoch 6/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2873 - accuracy: 0.3450 - val_loss: 2.2495 - val_accuracy: 0.3260\n",
            "Epoch 7/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2994 - accuracy: 0.3297 - val_loss: 2.2483 - val_accuracy: 0.3186\n",
            "Epoch 8/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2886 - accuracy: 0.3339 - val_loss: 2.2230 - val_accuracy: 0.3162\n",
            "Epoch 9/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2922 - accuracy: 0.3401 - val_loss: 2.2081 - val_accuracy: 0.3750\n",
            "Epoch 10/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2856 - accuracy: 0.3389 - val_loss: 2.2421 - val_accuracy: 0.3578\n",
            "Epoch 11/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2728 - accuracy: 0.3432 - val_loss: 2.2091 - val_accuracy: 0.3186\n",
            "Epoch 12/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3001 - accuracy: 0.3389 - val_loss: 2.2496 - val_accuracy: 0.3578\n",
            "Epoch 13/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3047 - accuracy: 0.3407 - val_loss: 2.2728 - val_accuracy: 0.3333\n",
            "Epoch 14/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3116 - accuracy: 0.3481 - val_loss: 2.2206 - val_accuracy: 0.3603\n",
            "Epoch 15/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2971 - accuracy: 0.3419 - val_loss: 2.2471 - val_accuracy: 0.3529\n",
            "Epoch 16/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2940 - accuracy: 0.3487 - val_loss: 2.2527 - val_accuracy: 0.3775\n",
            "Epoch 17/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2820 - accuracy: 0.3646 - val_loss: 2.2693 - val_accuracy: 0.3848\n",
            "Epoch 18/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2813 - accuracy: 0.3487 - val_loss: 2.3327 - val_accuracy: 0.3162\n",
            "Epoch 19/150\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 2.2950 - accuracy: 0.3493 - val_loss: 2.2178 - val_accuracy: 0.3260\n",
            "Epoch 20/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2660 - accuracy: 0.3634 - val_loss: 2.2524 - val_accuracy: 0.3358\n",
            "Epoch 21/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2802 - accuracy: 0.3524 - val_loss: 2.2150 - val_accuracy: 0.3260\n",
            "Epoch 22/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.2656 - accuracy: 0.3610 - val_loss: 2.2193 - val_accuracy: 0.3848\n",
            "Epoch 23/150\n",
            "51/51 [==============================] - 1s 17ms/step - loss: 2.2744 - accuracy: 0.3548 - val_loss: 2.3566 - val_accuracy: 0.3480\n",
            "Epoch 24/150\n",
            "51/51 [==============================] - 1s 16ms/step - loss: 2.3053 - accuracy: 0.3628 - val_loss: 2.2131 - val_accuracy: 0.3235\n",
            "Epoch 25/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2766 - accuracy: 0.3659 - val_loss: 2.1978 - val_accuracy: 0.3676\n",
            "Epoch 26/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2648 - accuracy: 0.3720 - val_loss: 2.1838 - val_accuracy: 0.3995\n",
            "Epoch 27/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2701 - accuracy: 0.3542 - val_loss: 2.2268 - val_accuracy: 0.3873\n",
            "Epoch 28/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2676 - accuracy: 0.3524 - val_loss: 2.1728 - val_accuracy: 0.4093\n",
            "Epoch 29/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2584 - accuracy: 0.3628 - val_loss: 2.2350 - val_accuracy: 0.3627\n",
            "Epoch 30/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2576 - accuracy: 0.3665 - val_loss: 2.1949 - val_accuracy: 0.3309\n",
            "Epoch 31/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2322 - accuracy: 0.3751 - val_loss: 2.1985 - val_accuracy: 0.3725\n",
            "Epoch 32/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2409 - accuracy: 0.3720 - val_loss: 2.1483 - val_accuracy: 0.4044\n",
            "Epoch 33/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2401 - accuracy: 0.3628 - val_loss: 2.2485 - val_accuracy: 0.3186\n",
            "Epoch 34/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2442 - accuracy: 0.3683 - val_loss: 2.1659 - val_accuracy: 0.3627\n",
            "Epoch 35/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2552 - accuracy: 0.3708 - val_loss: 2.1700 - val_accuracy: 0.3775\n",
            "Epoch 36/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2750 - accuracy: 0.3646 - val_loss: 2.1455 - val_accuracy: 0.3897\n",
            "Epoch 37/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2096 - accuracy: 0.3824 - val_loss: 2.1789 - val_accuracy: 0.3701\n",
            "Epoch 38/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2477 - accuracy: 0.3775 - val_loss: 2.1803 - val_accuracy: 0.3554\n",
            "Epoch 39/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2388 - accuracy: 0.3714 - val_loss: 2.1332 - val_accuracy: 0.3627\n",
            "Epoch 40/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2468 - accuracy: 0.3818 - val_loss: 2.1251 - val_accuracy: 0.3456\n",
            "Epoch 41/150\n",
            "51/51 [==============================] - 1s 15ms/step - loss: 2.2149 - accuracy: 0.3745 - val_loss: 2.1791 - val_accuracy: 0.3922\n",
            "Epoch 42/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1924 - accuracy: 0.3849 - val_loss: 2.1944 - val_accuracy: 0.4118\n",
            "Epoch 43/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2136 - accuracy: 0.4027 - val_loss: 2.2213 - val_accuracy: 0.3897\n",
            "Epoch 44/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2396 - accuracy: 0.3923 - val_loss: 2.2039 - val_accuracy: 0.4142\n",
            "Epoch 45/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2063 - accuracy: 0.3972 - val_loss: 2.1419 - val_accuracy: 0.3922\n",
            "Epoch 46/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2060 - accuracy: 0.3708 - val_loss: 2.3052 - val_accuracy: 0.3578\n",
            "Epoch 47/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2261 - accuracy: 0.3910 - val_loss: 2.1434 - val_accuracy: 0.3676\n",
            "Epoch 48/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.2064 - accuracy: 0.3972 - val_loss: 2.1516 - val_accuracy: 0.4363\n",
            "Epoch 49/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.1844 - accuracy: 0.3935 - val_loss: 2.1693 - val_accuracy: 0.4387\n",
            "Epoch 50/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1983 - accuracy: 0.3861 - val_loss: 2.1700 - val_accuracy: 0.3946\n",
            "Epoch 51/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.2064 - accuracy: 0.3935 - val_loss: 2.1615 - val_accuracy: 0.3676\n",
            "Epoch 52/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1852 - accuracy: 0.3886 - val_loss: 2.0659 - val_accuracy: 0.3750\n",
            "Epoch 53/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1972 - accuracy: 0.3720 - val_loss: 2.1206 - val_accuracy: 0.4142\n",
            "Epoch 54/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1895 - accuracy: 0.3794 - val_loss: 2.0729 - val_accuracy: 0.3775\n",
            "Epoch 55/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1906 - accuracy: 0.3775 - val_loss: 2.0980 - val_accuracy: 0.3431\n",
            "Epoch 56/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1758 - accuracy: 0.3886 - val_loss: 2.0826 - val_accuracy: 0.3505\n",
            "Epoch 57/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1644 - accuracy: 0.4009 - val_loss: 2.1155 - val_accuracy: 0.4338\n",
            "Epoch 58/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1289 - accuracy: 0.4002 - val_loss: 2.0879 - val_accuracy: 0.4338\n",
            "Epoch 59/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1498 - accuracy: 0.4211 - val_loss: 2.0941 - val_accuracy: 0.4093\n",
            "Epoch 60/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.1745 - accuracy: 0.3996 - val_loss: 2.1643 - val_accuracy: 0.3995\n",
            "Epoch 61/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1617 - accuracy: 0.3984 - val_loss: 2.1544 - val_accuracy: 0.3333\n",
            "Epoch 62/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1431 - accuracy: 0.4015 - val_loss: 2.0838 - val_accuracy: 0.4020\n",
            "Epoch 63/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1599 - accuracy: 0.4039 - val_loss: 2.1587 - val_accuracy: 0.3946\n",
            "Epoch 64/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1653 - accuracy: 0.3831 - val_loss: 2.1191 - val_accuracy: 0.4436\n",
            "Epoch 65/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1597 - accuracy: 0.4064 - val_loss: 2.0894 - val_accuracy: 0.4559\n",
            "Epoch 66/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1350 - accuracy: 0.3972 - val_loss: 2.0868 - val_accuracy: 0.4412\n",
            "Epoch 67/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1514 - accuracy: 0.4076 - val_loss: 2.1074 - val_accuracy: 0.3897\n",
            "Epoch 68/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1251 - accuracy: 0.3941 - val_loss: 2.0787 - val_accuracy: 0.4167\n",
            "Epoch 69/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1184 - accuracy: 0.4113 - val_loss: 2.0989 - val_accuracy: 0.4559\n",
            "Epoch 70/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1164 - accuracy: 0.4101 - val_loss: 2.0576 - val_accuracy: 0.3578\n",
            "Epoch 71/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.1158 - accuracy: 0.4064 - val_loss: 2.0693 - val_accuracy: 0.4265\n",
            "Epoch 72/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1269 - accuracy: 0.3935 - val_loss: 2.0958 - val_accuracy: 0.3971\n",
            "Epoch 73/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1405 - accuracy: 0.3837 - val_loss: 2.0543 - val_accuracy: 0.4142\n",
            "Epoch 74/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1207 - accuracy: 0.4021 - val_loss: 2.0722 - val_accuracy: 0.3848\n",
            "Epoch 75/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1159 - accuracy: 0.3972 - val_loss: 2.0729 - val_accuracy: 0.4363\n",
            "Epoch 76/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1266 - accuracy: 0.4064 - val_loss: 2.0081 - val_accuracy: 0.3971\n",
            "Epoch 77/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0964 - accuracy: 0.4168 - val_loss: 2.0047 - val_accuracy: 0.4142\n",
            "Epoch 78/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0790 - accuracy: 0.4119 - val_loss: 2.0189 - val_accuracy: 0.4191\n",
            "Epoch 79/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0986 - accuracy: 0.4027 - val_loss: 2.1054 - val_accuracy: 0.3946\n",
            "Epoch 80/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0974 - accuracy: 0.3972 - val_loss: 2.0766 - val_accuracy: 0.4387\n",
            "Epoch 81/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1085 - accuracy: 0.4058 - val_loss: 2.0556 - val_accuracy: 0.4240\n",
            "Epoch 82/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.1040 - accuracy: 0.4131 - val_loss: 2.0474 - val_accuracy: 0.3971\n",
            "Epoch 83/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0889 - accuracy: 0.4095 - val_loss: 2.0268 - val_accuracy: 0.4093\n",
            "Epoch 84/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1315 - accuracy: 0.4021 - val_loss: 2.0772 - val_accuracy: 0.3799\n",
            "Epoch 85/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0999 - accuracy: 0.4187 - val_loss: 2.0308 - val_accuracy: 0.4534\n",
            "Epoch 86/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1059 - accuracy: 0.4082 - val_loss: 2.0627 - val_accuracy: 0.3995\n",
            "Epoch 87/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1037 - accuracy: 0.3978 - val_loss: 1.9890 - val_accuracy: 0.4289\n",
            "Epoch 88/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0981 - accuracy: 0.4002 - val_loss: 2.0483 - val_accuracy: 0.3750\n",
            "Epoch 89/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0986 - accuracy: 0.4039 - val_loss: 2.0327 - val_accuracy: 0.3995\n",
            "Epoch 90/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0952 - accuracy: 0.4101 - val_loss: 2.0356 - val_accuracy: 0.4314\n",
            "Epoch 91/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0881 - accuracy: 0.3886 - val_loss: 2.0434 - val_accuracy: 0.3676\n",
            "Epoch 92/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0978 - accuracy: 0.4088 - val_loss: 2.0455 - val_accuracy: 0.4118\n",
            "Epoch 93/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0702 - accuracy: 0.4088 - val_loss: 2.0282 - val_accuracy: 0.4583\n",
            "Epoch 94/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0778 - accuracy: 0.4162 - val_loss: 2.0212 - val_accuracy: 0.4118\n",
            "Epoch 95/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1057 - accuracy: 0.4045 - val_loss: 1.9845 - val_accuracy: 0.3995\n",
            "Epoch 96/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0538 - accuracy: 0.4064 - val_loss: 2.0941 - val_accuracy: 0.4118\n",
            "Epoch 97/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0522 - accuracy: 0.4230 - val_loss: 2.0301 - val_accuracy: 0.4510\n",
            "Epoch 98/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0828 - accuracy: 0.4070 - val_loss: 2.0087 - val_accuracy: 0.3995\n",
            "Epoch 99/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.1029 - accuracy: 0.4070 - val_loss: 2.0215 - val_accuracy: 0.4338\n",
            "Epoch 100/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0719 - accuracy: 0.4156 - val_loss: 2.0267 - val_accuracy: 0.4755\n",
            "Epoch 101/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0643 - accuracy: 0.4187 - val_loss: 2.0098 - val_accuracy: 0.4485\n",
            "Epoch 102/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0739 - accuracy: 0.4119 - val_loss: 1.9973 - val_accuracy: 0.4289\n",
            "Epoch 103/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0705 - accuracy: 0.4144 - val_loss: 2.0428 - val_accuracy: 0.4191\n",
            "Epoch 104/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0682 - accuracy: 0.3990 - val_loss: 1.9940 - val_accuracy: 0.4240\n",
            "Epoch 105/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0607 - accuracy: 0.4027 - val_loss: 2.0030 - val_accuracy: 0.4020\n",
            "Epoch 106/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0534 - accuracy: 0.4205 - val_loss: 1.9979 - val_accuracy: 0.4828\n",
            "Epoch 107/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0835 - accuracy: 0.3917 - val_loss: 2.0068 - val_accuracy: 0.4167\n",
            "Epoch 108/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0560 - accuracy: 0.4125 - val_loss: 1.9848 - val_accuracy: 0.4020\n",
            "Epoch 109/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0861 - accuracy: 0.4131 - val_loss: 2.0144 - val_accuracy: 0.3676\n",
            "Epoch 110/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0556 - accuracy: 0.3990 - val_loss: 2.0436 - val_accuracy: 0.4240\n",
            "Epoch 111/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0747 - accuracy: 0.3898 - val_loss: 1.9837 - val_accuracy: 0.4142\n",
            "Epoch 112/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0381 - accuracy: 0.4107 - val_loss: 1.9873 - val_accuracy: 0.4044\n",
            "Epoch 113/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0707 - accuracy: 0.4125 - val_loss: 1.9513 - val_accuracy: 0.4632\n",
            "Epoch 114/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0377 - accuracy: 0.4138 - val_loss: 1.9496 - val_accuracy: 0.4142\n",
            "Epoch 115/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0309 - accuracy: 0.4199 - val_loss: 1.9934 - val_accuracy: 0.4387\n",
            "Epoch 116/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0605 - accuracy: 0.4052 - val_loss: 1.9934 - val_accuracy: 0.3922\n",
            "Epoch 117/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0458 - accuracy: 0.4033 - val_loss: 1.9714 - val_accuracy: 0.4412\n",
            "Epoch 118/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0396 - accuracy: 0.4095 - val_loss: 1.9816 - val_accuracy: 0.4314\n",
            "Epoch 119/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0497 - accuracy: 0.4162 - val_loss: 1.9869 - val_accuracy: 0.3897\n",
            "Epoch 120/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0599 - accuracy: 0.4101 - val_loss: 2.0190 - val_accuracy: 0.3873\n",
            "Epoch 121/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0469 - accuracy: 0.4052 - val_loss: 1.9844 - val_accuracy: 0.4314\n",
            "Epoch 122/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0444 - accuracy: 0.4193 - val_loss: 1.9643 - val_accuracy: 0.4828\n",
            "Epoch 123/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0607 - accuracy: 0.4144 - val_loss: 2.0064 - val_accuracy: 0.4216\n",
            "Epoch 124/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0666 - accuracy: 0.4119 - val_loss: 1.9629 - val_accuracy: 0.4559\n",
            "Epoch 125/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0443 - accuracy: 0.4279 - val_loss: 1.9829 - val_accuracy: 0.4314\n",
            "Epoch 126/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0439 - accuracy: 0.4162 - val_loss: 1.9708 - val_accuracy: 0.4510\n",
            "Epoch 127/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0658 - accuracy: 0.4138 - val_loss: 1.9650 - val_accuracy: 0.4338\n",
            "Epoch 128/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0085 - accuracy: 0.4303 - val_loss: 2.0018 - val_accuracy: 0.4559\n",
            "Epoch 129/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0534 - accuracy: 0.4144 - val_loss: 1.9927 - val_accuracy: 0.4338\n",
            "Epoch 130/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0332 - accuracy: 0.4131 - val_loss: 1.9519 - val_accuracy: 0.4461\n",
            "Epoch 131/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0360 - accuracy: 0.4033 - val_loss: 1.9294 - val_accuracy: 0.4265\n",
            "Epoch 132/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0379 - accuracy: 0.4266 - val_loss: 1.9658 - val_accuracy: 0.4289\n",
            "Epoch 133/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0443 - accuracy: 0.4144 - val_loss: 1.9460 - val_accuracy: 0.4436\n",
            "Epoch 134/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0274 - accuracy: 0.4101 - val_loss: 1.9296 - val_accuracy: 0.4559\n",
            "Epoch 135/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0138 - accuracy: 0.4260 - val_loss: 1.9912 - val_accuracy: 0.4412\n",
            "Epoch 136/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0161 - accuracy: 0.4242 - val_loss: 1.9413 - val_accuracy: 0.4559\n",
            "Epoch 137/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0050 - accuracy: 0.4279 - val_loss: 1.9947 - val_accuracy: 0.4363\n",
            "Epoch 138/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0390 - accuracy: 0.4168 - val_loss: 1.9814 - val_accuracy: 0.4167\n",
            "Epoch 139/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0085 - accuracy: 0.4303 - val_loss: 1.9368 - val_accuracy: 0.4853\n",
            "Epoch 140/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0169 - accuracy: 0.4193 - val_loss: 1.9579 - val_accuracy: 0.4338\n",
            "Epoch 141/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0806 - accuracy: 0.4156 - val_loss: 1.9690 - val_accuracy: 0.4534\n",
            "Epoch 142/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0509 - accuracy: 0.4193 - val_loss: 1.9388 - val_accuracy: 0.4265\n",
            "Epoch 143/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0238 - accuracy: 0.4045 - val_loss: 1.9461 - val_accuracy: 0.4583\n",
            "Epoch 144/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0565 - accuracy: 0.4193 - val_loss: 1.9690 - val_accuracy: 0.4779\n",
            "Epoch 145/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0412 - accuracy: 0.4187 - val_loss: 1.9590 - val_accuracy: 0.4338\n",
            "Epoch 146/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0360 - accuracy: 0.4168 - val_loss: 1.9179 - val_accuracy: 0.4461\n",
            "Epoch 147/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0300 - accuracy: 0.4303 - val_loss: 1.9281 - val_accuracy: 0.4216\n",
            "Epoch 148/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0215 - accuracy: 0.4236 - val_loss: 1.9464 - val_accuracy: 0.4240\n",
            "Epoch 149/150\n",
            "51/51 [==============================] - 1s 14ms/step - loss: 2.0226 - accuracy: 0.4223 - val_loss: 1.9832 - val_accuracy: 0.3775\n",
            "Epoch 150/150\n",
            "51/51 [==============================] - 1s 13ms/step - loss: 2.0215 - accuracy: 0.4125 - val_loss: 1.9642 - val_accuracy: 0.4387\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "history_2 = model_2.fit(X_train, y_train, epochs=150, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('model_cnn2.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test).argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 3 1 5 1 7 1 5 1 1 1 1 3 3 1 7 1 5 3 1 5 5 1 1 7 3 1 5 1 5 1 1 7 3 1\n",
            " 5 1 3 3 1 5 7 5 3 5 1 1 7 1 1 1 7 1 1 3 3 3 5 5 3 1 1 3 7 7 1 1 5 1 1 1 1\n",
            " 5 1 5 1 8 1 1 1 1 5 1 1 1 5 1 3 1 5 3 1 1 1 3 3 5 1 5 1 1 1 5 5 3 1 3 1 1\n",
            " 1 1 5 1 1 1 1 7 1 3 3 1 5 3 1 1 5 1 1 5 1 1 3 1 5 1 1 8 5 5 7 1 1 1 3 1 1\n",
            " 1 1 1 1 5 1 5 1 3 5 1 7 1 1 1 5 3 1 5 5 1 1 5 3 1 3 5 1 5 1 3 1 5 1 5 1 1\n",
            " 1 1 1 1 1 5 5 5 3 1 5 1 1 5 1 1 5 5 3 1 1 1 1 3 5 1 3 1 5 5 1 1 3 5 1 1 1\n",
            " 1 1 1 3 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 1 3 2 8 3 1 5 1 1 1 1 2 1 0 8 7 5 3 9 3 8 1 1 3 8 5 1 3 1 5 5 5 3 2 7 5\n",
            " 1 9 1 8 1 6 6 8 1 4 1 3 1 1 3 6 5 8 3 8 8 2 7 8 1 0 3 0 5 3 3 3 2 7 1 1 8\n",
            " 1 8 3 3 0 3 1 1 1 4 0 0 1 5 1 1 1 1 4 1 5 5 1 1 3 8 0 1 9 8 1 8 8 3 1 5 3\n",
            " 3 8 7 0 7 8 3 8 3 7 5 3 8 1 2 5 1 1 3 1 1 3 6 7 3 0 2 0 3 9 7 3 8 3 1 8 5\n",
            " 8 8 5 1 1 5 1 8 3 1 3 5 3 7 1 1 3 1 2 8 3 6 2 8 1 0 3 1 3 8 4 1 1 5 3 5 1\n",
            " 1 3 1 3 5 5 5 2 3 8 7 1 9 7 5 1 5 3 7 1 2 1 3 3 3 1 5 7 5 0 1 5 3 8 8 7 3\n",
            " 1 5 8 3 1]\n"
          ]
        }
      ],
      "source": [
        "y_test_final = []\n",
        "for i in y_test:\n",
        "    y_test_final.extend(np.where(i==1)[0])\n",
        "y_test_final = np.array(y_test_final)\n",
        "print(y_test_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test = np.array(y_test).argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "         material fact       0.00      0.00      0.00        11\n",
            "       procedural fact       0.37      0.79      0.50        58\n",
            "            allegation       0.00      0.00      0.00         5\n",
            "       defendant claim       0.53      0.35      0.42        54\n",
            "         issues framed       0.00      0.00      0.00         1\n",
            "        statutory fact       0.40      0.64      0.49        33\n",
            "subjective observation       0.00      0.00      0.00        10\n",
            "             violation       0.67      0.32      0.43        25\n",
            "               penalty       0.50      0.04      0.07        26\n",
            "          related fact       0.00      0.00      0.00         4\n",
            "\n",
            "              accuracy                           0.42       227\n",
            "             macro avg       0.25      0.21      0.19       227\n",
            "          weighted avg       0.41      0.42      0.36       227\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "D:\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.41291992839923486"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JfgiWqbalgq",
        "outputId": "bc2984da-c177-4e63-a0c4-b1e9a5047660"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-24-f974fb20e58e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "print(classification_report(data.test_y, y_pred, target_names=classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2xkyASSaokK"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=data.test_y, y_pred= y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ffUMItg-kS3X",
        "outputId": "842f6409-9497-4ab6-df51-5a34817d127b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "height, width = cm.shape\n",
        "print(height)\n",
        "print(width)\n",
        "\n",
        "fig = plt.figure('confusion matrix')\n",
        "ax = fig.add_subplot(111, aspect='equal')\n",
        "for x in range(height):\n",
        "    rowsum = 0\n",
        "    for y in range(width):\n",
        "      if x == y:\n",
        "        ax.annotate(str(cm[width-x-1][height-y-1]), xy=(y, x), ha='center', va='center',backgroundcolor='#ADD8E6')\n",
        "        rowsum += cm[width-x-1][height-y-1]\n",
        "      else:\n",
        "        ax.annotate(str(cm[width-x-1][height-y-1]), xy=(y, x), ha='center', va='center')\n",
        "        rowsum += cm[width-x-1][height-y-1] \n",
        "    #print(f'row {x} sum is {rowsum}')\n",
        "    for y in range(width):\n",
        "      if x == y:\n",
        "        pass\n",
        "      elif cm[width-x-1][height-y-1] > int(0.1*rowsum):\n",
        "        ax.annotate(str(cm[width-x-1][height-y-1]), xy=(y, x), ha='center', va='center',backgroundcolor='#ffcccb')\n",
        "    \n",
        "\n",
        "offset = .5    \n",
        "ax.set_xlim(-offset, width - offset)\n",
        "ax.set_ylim(-offset, height - offset)\n",
        "\n",
        "ax.hlines(y=np.arange(height+1)- offset, xmin=-offset, xmax=width-offset)\n",
        "ax.vlines(x=np.arange(width+1) - offset, ymin=-offset, ymax=height-offset)\n",
        "\n",
        "\n",
        "\n",
        "plt.xticks(range(width), classes,rotation=90)\n",
        "plt.yticks(range(height), classes)\n",
        "plt.savefig('confusion_matrix.png', format='png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNCuYHO5Q3QcLWMlFxLRQsy",
      "collapsed_sections": [],
      "mount_file_id": "1Or55t1EafsCuturvOp4ME0mfozwHXD4M",
      "name": "left_right_context_model_alternate.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "37b255bb5dc0d995b91bd1b934b878e610a26475f52eafaf29fdb395fb105534"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
